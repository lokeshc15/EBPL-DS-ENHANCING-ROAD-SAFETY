# -*- coding: utf-8 -*-
"""Untitled9.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zUNpiHcnpBsIwWxP3GiCNGZBsrbUHVya
"""

import cv2
import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans

def extract_dominant_colors(image_path, k=5):
    # Load image using OpenCV
    image = cv2.imread(image_path)
    if image is None:
        raise ValueError(f"Image not found at path: {image_path}")

    # Convert image from BGR (OpenCV default) to RGB
    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

    # Reshape image to a 2D array of pixels
    pixels = image_rgb.reshape(-1, 3)

    # Apply KMeans clustering to find dominant colors
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(pixels)

    # Get the cluster centers (dominant colors) and labels
    dominant_colors = np.array(kmeans.cluster_centers_, dtype='uint8')
    labels = kmeans.labels_

    return image_rgb, dominant_colors, labels

def plot_dominant_colors(image_rgb, dominant_colors, labels):
    # Calculate the proportion of each cluster
    label_counts = np.bincount(labels)
    total_count = np.sum(label_counts)
    proportions = label_counts / total_count

    # Sort colors by proportion
    sorted_indices = np.argsort(-proportions)
    dominant_colors = dominant_colors[sorted_indices]
    proportions = proportions[sorted_indices]

    # Create a color bar
    bar_height = 50
    bar_width = 300
    color_bar = np.zeros((bar_height, bar_width, 3), dtype='uint8')
    start_x = 0

    for proportion, color in zip(proportions, dominant_colors):
        end_x = start_x + int(proportion * bar_width)
        cv2.rectangle(color_bar, (start_x, 0), (end_x, bar_height), color.tolist(), -1)
        start_x = end_x

    # Display the image and color bar
    plt.figure(figsize=(8, 6))
    plt.subplot(2, 1, 1)
    plt.imshow(image_rgb)
    plt.axis('off')
    plt.title('Original Image')

    plt.subplot(2, 1, 2)
    plt.imshow(color_bar)
    plt.axis('off')
    plt.title('Dominant Colors')

    plt.tight_layout()
    plt.show()

# Example usage
if __name__ == "__main__":
    image_path = 'path_to_your_image.jpg'  # Replace with your image path
    k = 5  # Number of dominant colors to extract

    image_rgb, dominant_colors, labels = extract_dominant_colors(image_path, k)
    plot_dominant_colors(image_rgb, dominant_colors, labels)

import cv2
import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from collections import Counter
from skimage.color import rgb2lab, deltaE_cie76
import webcolors

def RGB2HEX(color):
    return "#{:02x}{:02x}{:02x}".format(int(color[0]), int(color[1]), int(color[2]))

def get_colors(image, number_of_colors, show_chart=True):
    # Resize image for faster processing
    modified_image = cv2.resize(image, (600, 400), interpolation=cv2.INTER_AREA)
    modified_image = modified_image.reshape(modified_image.shape[0]*modified_image.shape[1], 3)

    # Apply K-means clustering
    clf = KMeans(n_clusters=number_of_colors)
    labels = clf.fit_predict(modified_image)

    counts = Counter(labels)
    counts = dict(sorted(counts.items()))

    center_colors = clf.cluster_centers_
    ordered_colors = [center_colors[i] for i in counts.keys()]
    hex_colors = [RGB2HEX(ordered_colors[i]) for i in counts.keys()]
    rgb_colors = [ordered_colors[i] for i in counts.keys()]

    if show_chart:
        plt.figure(figsize=(8, 6))
        plt.pie(counts.values(), labels=hex_colors, colors=hex_colors)
        plt.title(f'Top {number_of_colors} Dominant Colors')
        plt.show()

    return rgb_colors

def closest_color(requested_color):
    min_colors = {}
    for key, name in webcolors.CSS3_HEX_TO_NAMES.items():
        r_c, g_c, b_c = webcolors.hex_to_rgb(key)
        rd = (r_c - requested_color[0]) ** 2
        gd = (g_c - requested_color[1]) ** 2
        bd = (b_c - requested_color[2]) ** 2
        min_colors[(rd + gd + bd)] = name
    return min_colors[min(min_colors.keys())]

def color_detection(image_path, num_colors=5, threshold=50):
    # Read and convert image
    image = cv2.imread(image_path)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

    # Get dominant colors
    print("Extracting dominant colors...")
    colors = get_colors(image, num_colors)

    # Display original image
    plt.figure(figsize=(10, 8))
    plt.subplot(1, 2, 1)
    plt.imshow(image)
    plt.title('Original Image')
    plt.axis('off')

    # Create color palette
    plt.subplot(1, 2, 2)
    color_patches = []
    color_names = []

    for i, color in enumerate(colors):
        color_patch = np.zeros((100, 100, 3), dtype=np.uint8)
        color_patch[:, :] = color
        color_patches.append(color_patch)
        try:
            color_name = webcolors.rgb_to_name((int(color[0]), int(color[1]), int(color[2])))
        except ValueError:
            color_name = closest_color((int(color[0]), int(color[1]), int(color[2])))
        color_names.append(f"{RGB2HEX(color)}: {color_name}")

    # Display color palette with names
    palette = np.vstack(color_patches)
    plt.imshow(palette)
    plt.title('Detected Colors')
    plt.axis('off')

    # Add color labels
    for i, name in enumerate(color_names):
        plt.text(50, 110 + i*100, name, ha='center', fontsize=10)

    plt.tight_layout()
    plt.show()

    return colors

def detect_specific_color(image_path, target_color_hex, color_name="Target Color"):
    # Convert target color
    target_color_rgb = webcolors.hex_to_rgb(target_color_hex)
    target_color_lab = rgb2lab(np.uint8([[target_color_rgb]]))[0][0]

    # Read and process image
    image = cv2.imread(image_path)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    lab_image = rgb2lab(image)

    # Calculate color difference
    mask = np.zeros(lab_image.shape[:2])
    for i in range(lab_image.shape[0]):
        for j in range(lab_image.shape[1]):
            diff = deltaE_cie76(target_color_lab, lab_image[i][j])
            mask[i][j] = diff

    # Apply threshold (lower values mean closer match)
    threshold = 30
    detected_areas = mask < threshold

    # Create output visualization
    plt.figure(figsize=(15, 5))

    # Original image
    plt.subplot(1, 3, 1)
    plt.imshow(image)
    plt.title('Original Image')
    plt.axis('off')

    # Color difference map
    plt.subplot(1, 3, 2)
    plt.imshow(mask, cmap='viridis')
    plt.colorbar()
    plt.title('Color Difference Map')
    plt.axis('off')

    # Detected areas
    plt.subplot(1, 3, 3)
    output_image = image.copy()
    output_image[~detected_areas] = output_image[~detected_areas] * 0.3  # Dim non-matching areas
    plt.imshow(output_image)
    plt.title(f'Detected {color_name} Areas')
    plt.axis('off')

    plt.tight_layout()
    plt.show()

# Example usage
if __name__ == "__main__":
    # Download an example image or use your own
    image_url = "https://images.unsplash.com/photo-1535478044878-3ed83d5456ef"
    image_path = "sample_image.jpg"

    # Download image if not exists
    import os
    if not os.path.exists(image_path):
        import urllib.request
        urllib.request.urlretrieve(image_url, image_path)

    # 1. Detect dominant colors
    print("Running dominant color detection...")
    detected_colors = color_detection(image_path, num_colors=5)

    # 2. Detect specific color (red in this example)
    print("\nRunning specific color detection (red)...")
    detect_specific_color(image_path, "#FF0000", "Red")